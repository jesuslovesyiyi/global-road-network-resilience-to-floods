{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a list of 10 different flood return periods\n",
    "RP_lst = [5, 10, 20, 50, 75, 100, 200, 250, 500, 1000]\n",
    "\n",
    "# Directory where graphs with flood inundation levels attached to the nodes and edges\n",
    "flooded_graphs_2616_dir = 'L:/yiyi/2616_flooded_graphs_drive_servce_no_res/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T05:57:30.200435Z",
     "start_time": "2023-04-11T05:57:30.195560Z"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate through 10 flood return periods\n",
    "for rp in RP_lst:\n",
    "    # Print return period\n",
    "    print('RP=' + str(rp))\n",
    "    \n",
    "    # Iterate through graphs in the directory\n",
    "    for flooded_graph_file in os.listdir(flooded_graphs_2616_dir):\n",
    "        # Find network id\n",
    "        net_id = int(flooded_graph_file[11:][:-13])\n",
    "        print('net_id='+ str(net_id))\n",
    "        \n",
    "        # Load graph\n",
    "        G_flooded =  pickle.load(open(flooded_graphs_2616_dir + flooded_graph_file, 'rb'))\n",
    "        # Make a copy of the graph\n",
    "        G_disrupted = G_flooded.copy()\n",
    "\n",
    "        # Delete nodes with flood inundation greater than 30cm or 0.3m\n",
    "        for node_id, node_data in G_flooded.nodes.data():\n",
    "            if node_data['FUP_' + str(rp)] >= 0.3:\n",
    "                G_disrupted.remove_node(node_id)\n",
    "\n",
    "        print('removed: '+ str(G_disrupted.number_of_nodes()) + ' from ' + str(G_flooded.number_of_nodes()))\n",
    "        # Add original/dry speed\n",
    "        try:\n",
    "            G_disrupted_speed = ox.speed.add_edge_speeds(G_disrupted)\n",
    "            print('finished adding ori speed')\n",
    "        except:\n",
    "            print('CANNOT add ori speed')\n",
    "            continue\n",
    "        # Alter the maximum travel speed for edges\n",
    "        # Reference paper:\n",
    "        # Pregnolato, Maria, et al. \"The impact of flooding on road transport: A depth-disruption function.\"\n",
    "        # Transportation research part D: transport and environment 55 (2017): 67-81.\n",
    "        for start_id, end_id, edge_data in G_disrupted_speed.edges.data():\n",
    "            edge_water_depth_mm = max(G_disrupted_speed.nodes[start_id]['FUP_'+str(rp)], G_disrupted_speed.nodes[end_id]['FUP_'+str(rp)])\n",
    "            theoretical_speed = 86.9448 - (0.5529*edge_water_depth_mm) + (0.0009*edge_water_depth_mm*edge_water_depth_mm)\n",
    "            designed_speed = edge_data['speed_kph']\n",
    "            G_disrupted_speed[start_id][end_id][0]['speed_kph'] = min(theoretical_speed, designed_speed)\n",
    "        try:\n",
    "            G_disrupted_speed_time = ox.speed.add_edge_travel_times(G_disrupted_speed)\n",
    "            print('finished changing speed')\n",
    "        except:\n",
    "            print('CANNOT disrupt speed and time')\n",
    "        # Save disrupted graphs    \n",
    "        with open('L:/yiyi/2616_disrupted_graphs/FUP_' + str(rp) + '/G_' + str(net_id) + '_disrupted_FUP_' + str(rp) + '.pk', 'wb') as handle:\n",
    "            pickle.dump(G_disrupted_speed_time, handle, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wb3",
   "language": "python",
   "name": "wb3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
